{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:38.460412Z",
     "start_time": "2025-04-26T17:41:36.371814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "id": "52041f54259396d6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:38.463694Z",
     "start_time": "2025-04-26T17:41:38.461766Z"
    }
   },
   "cell_type": "code",
   "source": "warnings.filterwarnings('ignore')",
   "id": "1607bb44c9ca7bba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:38.466026Z",
     "start_time": "2025-04-26T17:41:38.464328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##\n",
    "# pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.options.display.max_columns = None"
   ],
   "id": "d2e23c56a02a6836",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:38.468013Z",
     "start_time": "2025-04-26T17:41:38.466635Z"
    }
   },
   "cell_type": "code",
   "source": "VER = 1",
   "id": "d641d106d809006e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.093231Z",
     "start_time": "2025-04-26T17:41:38.469204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "print(train.shape)"
   ],
   "id": "76b8a6f2cfe4cba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 12)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FE",
   "id": "7912cfd1a2ad608b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.095959Z",
     "start_time": "2025-04-26T17:41:39.093961Z"
    }
   },
   "cell_type": "code",
   "source": "y = train['Listening_Time_minutes']",
   "id": "a3fee948c6ac8a57",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.099384Z",
     "start_time": "2025-04-26T17:41:39.097291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DROP_COLS = ['id']\n",
    "TARGET_COL = ['Listening_Time_minutes']\n",
    "CAT_COLS = ['Podcast_Name', 'Episode_Title', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']"
   ],
   "id": "7b2b0048806758af",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.101978Z",
     "start_time": "2025-04-26T17:41:39.100064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def fe(df):\n",
    "#     train['isnull_Episode_Length_minutes'] = train['Episode_Length_minutes'].isnull().astype(int)\n",
    "#     \n",
    "#     train[\"NaNs\"] = np.float32(0)\n",
    "#     for i, c in enumerate(train.columns):\n",
    "#         train[\"NaNs\"] += train[c].isna() * 2 ** i\n",
    "#     \n",
    "#     for k in range(1, 10):\n",
    "#         train[f'elm_digit{k}'] = ((train['Episode_Length_minutes'] * 10 ** k) % 10).fillna(-1).astype(\"int8\")    \n",
    "# \n",
    "# \n",
    "#     #  First we label encode the original categorical column into integers with -1 being NAN\n",
    "#     for i, c in enumerate(CAT_COLS):\n",
    "#         combine = pd.concat([train[c], test[c]], axis=0)\n",
    "#         combine, _ = pd.factorize(combine)\n",
    "#         train[c] = combine[:len(train)]\n",
    "#         test[c] = combine[len(train):]\n",
    "#         \n",
    "#     # Then we combine the integers\n",
    "#     COMBO = []\n",
    "#     for i, c1 in enumerate(CAT_COLS[:-1]):\n",
    "#         for j, c2 in enumerate(CAT_COLS[i + 1:]):\n",
    "#             n = f\"{c1}_{c2}\"\n",
    "#             m1 = train[c1].max() + 1\n",
    "#             m2 = train[c2].max() + 1\n",
    "#             train[n] = ((train[c1] + 1 + (train[c2] + 1) / (m2 + 1)) * (m2 + 1)).astype(\"int8\")\n",
    "#             m1 = test[c1].max() + 1\n",
    "#             m2 = test[c2].max() + 1\n",
    "#             test[n] = ((test[c1] + 1 + (test[c2] + 1) / (m2 + 1)) * (m2 + 1)).astype(\"int8\")\n",
    "#             COMBO.append(n)\n",
    "#     \n",
    "#     return COMBO            \n"
   ],
   "id": "ef4cb41b93cc7652",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### isNan Episode_Length_minutes",
   "id": "f6ade0b0c0b2f56c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.104367Z",
     "start_time": "2025-04-26T17:41:39.102778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train['isnull_Episode_Length_minutes'] = train['Episode_Length_minutes'].isnull().astype(int)\n",
    "# test['isnull_Episode_Length_minutes'] = test['Episode_Length_minutes'].isnull().astype(int)\n",
    "# CAT_COLS.append('isnull_Episode_Length_minutes')\n"
   ],
   "id": "98fff402be9e0e78",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### All NANs as Single Base-2 Column",
   "id": "5a6fac6ae37ac061"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.106612Z",
     "start_time": "2025-04-26T17:41:39.105042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train[\"NaNs\"] = np.float32(0)\n",
    "# test[\"NaNs\"] = np.float32(0)\n",
    "# for i, c in enumerate(test.columns):\n",
    "#     train[\"NaNs\"] += train[c].isna() * 2 ** i\n",
    "#     test[\"NaNs\"] += test[c].isna() * 2 ** i\n",
    "# \n",
    "# CAT_COLS.append('NaNs')"
   ],
   "id": "88652722e13a61df",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract Float32 as Digits from Episode_Length_minutes",
   "id": "df3dc220ebb03b70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.108807Z",
     "start_time": "2025-04-26T17:41:39.107332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for k in range(1, 10):\n",
    "#     train[f'elm_digit{k}'] = ((train['Episode_Length_minutes'] * 10 ** k) % 10).fillna(-1).astype(\"int8\")\n",
    "#     test[f'elm_digit{k}'] = ((test['Episode_Length_minutes'] * 10 ** k) % 10).fillna(-1).astype(\"int8\")\n"
   ],
   "id": "296270634bc8e5b4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Combination of Categorical Columns",
   "id": "baba0ed5d37c80a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.356545Z",
     "start_time": "2025-04-26T17:41:39.109465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #  First we label encode the original categorical column into integers with -1 being NAN\n",
    "# for i, c in enumerate(CAT_COLS):\n",
    "#     combine = pd.concat([train[c], test[c]], axis=0)\n",
    "#     combine, _ = pd.factorize(combine)\n",
    "#     train[c] = combine[:len(train)]\n",
    "#     test[c] = combine[len(train):]"
   ],
   "id": "a7329caf4104d169",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.473890Z",
     "start_time": "2025-04-26T17:41:39.357598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Then we combine the integers\n",
    "# COMBO = []\n",
    "# for i, c1 in enumerate(CAT_COLS[:-1]):\n",
    "#     for j, c2 in enumerate(CAT_COLS[i + 1:]):\n",
    "#         n = f\"{c1}_{c2}\"\n",
    "#         m1 = train[c1].max() + 1\n",
    "#         m2 = train[c2].max() + 1\n",
    "#         train[n] = ((train[c1] + 1 + (train[c2] + 1) / (m2 + 1)) * (m2 + 1)).astype(\"int8\")\n",
    "#         m1 = test[c1].max() + 1\n",
    "#         m2 = test[c2].max() + 1\n",
    "#         test[n] = ((test[c1] + 1 + (test[c2] + 1) / (m2 + 1)) * (m2 + 1)).astype(\"int8\")\n",
    "#         COMBO.append(n)\n",
    "# \n",
    "# CAT_COLS.extend(COMBO)"
   ],
   "id": "68ac621bc415f789",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Groupby(COL1)['Listening_Time_minutes'].agg(HISTOGRAM BINS)\n",
   "id": "2a05eae330c5bf23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.478212Z",
     "start_time": "2025-04-26T17:41:39.476086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_histogram(series, bins=5):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        series (pd.Series): The price values for a group.\n",
    "        bins (int): Number of equally spaced bins.\n",
    "    \"\"\"\n",
    "    series_clean = series.dropna()\n",
    "    counts, bin_edges = np.histogram(series_clean, bins=bins)\n",
    "    counts_reshaped = counts.reshape((-1, len(counts)))\n",
    "    data = pd.DataFrame(counts_reshaped, columns=[f\"ltm_bin_{i}\" for i in range(len(counts))])\n",
    "    data['nan_count'] = series.isna().sum()\n",
    "    return data"
   ],
   "id": "86a1d3149fbfa008",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Groupby(COL1)['Listening_Time_minutes'].agg(QUANTILES)\n",
   "id": "2b8c127b3d6ef727"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.481067Z",
     "start_time": "2025-04-26T17:41:39.478949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "QUANTILES = [0.05, 0.1, 0.4, 0.45, 0.55, 0.6, 0.9, 0.95]\n",
    "\n",
    "\n",
    "def quant(series):\n",
    "    quantils = np.quantile(series, QUANTILES)\n",
    "    quantils_reshaped = quantils.reshape((-1, len(quantils)))\n",
    "    return pd.DataFrame(quantils_reshaped, columns=[f\"quantils_bin_{int(i * 100)}\" for i in QUANTILES])"
   ],
   "id": "11aedadec21572a5",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create columns lists",
   "id": "aa1c9c4d3da45912"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:39.483787Z",
     "start_time": "2025-04-26T17:41:39.481901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_COLS = [col for col in train.columns if col not in DROP_COLS + CAT_COLS + TARGET_COL]\n",
    "FEATURES = CAT_COLS + NUM_COLS"
   ],
   "id": "89f06194fbe33305",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T17:42:06.423410Z",
     "start_time": "2025-04-26T17:42:06.420818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# STATISTICS TO AGGREGATE FOR OUR FEATURE GROUPS\n",
    "STATS = [\"mean\", \"std\", \"count\", \"nunique\", \"median\", \"min\", \"max\", \"skew\"]\n",
    "STATS2 = [\"mean\", \"std\"]"
   ],
   "id": "6038e5121800dea7",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## KFOLD ",
   "id": "2a10272f79e871aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:29:18.303904Z",
     "start_time": "2025-04-26T17:42:06.446567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "ParamsXGB = {'max_depth': 10, 'learning_rate': 0.00462847749422193, 'min_child_weight': 4, \n",
    "             'subsample': 0.8244361720956633, 'colsample_bytree': 0.5586626138810886, \n",
    "             'gamma': 1.1614500954011453, 'reg_alpha': 0.3548920754067436, 'reg_lambda': 3.9465129148897287,\n",
    "             \"n_estimators\": 50000, 'enable_categorical':True,}\n",
    "\n",
    "FOLDS = 5\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "oof = np.zeros((len(train)))\n",
    "pred = np.zeros((len(test)))\n",
    "\n",
    "# OUTER K FOLD\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    print(f\"### OUTER Fold {i + 1} ###\")\n",
    "\n",
    "    X_train = train.loc[train_index, FEATURES + TARGET_COL].reset_index(drop=True).copy()\n",
    "    y_train = train.loc[train_index, 'Listening_Time_minutes']\n",
    "\n",
    "    X_valid = train.loc[test_index, FEATURES].reset_index(drop=True).copy()\n",
    "    y_valid = train.loc[test_index, 'Listening_Time_minutes']\n",
    "\n",
    "    X_test = test[FEATURES].reset_index(drop=True).copy()\n",
    "\n",
    "    # INNER K FOLD (TO PREVENT LEAKAGE WHEN USING Listening_Time_minutes)\n",
    "    kf2 = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    for j, (train_index2, test_index2) in enumerate(kf2.split(X_train)):\n",
    "        print(f\" ## INNER Fold {j + 1} (outer fold {i + 1}) ##\")\n",
    "\n",
    "        X_train2 = X_train.loc[train_index2, FEATURES + TARGET_COL].copy()\n",
    "        X_valid2 = X_train.loc[test_index2, FEATURES].copy()\n",
    "\n",
    "        ### FEATURE SET 1 (uses Listening_Time_minutes) ###\n",
    "        col = \"Episode_Length_minutes\"\n",
    "        tmp = X_train2.groupby(col).Listening_Time_minutes.apply(quant)\n",
    "        tmp.columns = [f\"TE1_elm_{s}\" for s in tmp.columns]\n",
    "        X_valid2 = X_valid2.merge(tmp, on=col, how=\"left\")\n",
    "        for c in tmp.columns:\n",
    "            X_train.loc[test_index2, c] = X_valid2[c].values\n",
    "        \n",
    "        ### FEATURE SET 2 (uses Listening_Time_minutes) ###\n",
    "        for col in CAT_COLS:\n",
    "            tmp = X_train2.groupby(col).Listening_Time_minutes.apply(quant)\n",
    "            tmp.columns = [f\"TE2_{col}_{s}\" for s in tmp.columns]\n",
    "            X_valid2 = X_valid2.merge(tmp, on=col, how=\"left\")\n",
    "            for c in tmp.columns:\n",
    "                X_train.loc[test_index2, c] = X_valid2[c].values\n",
    "\n",
    "    ### FEATURE SET 1 (uses Listening_Time_minutes) ###\n",
    "    col = \"Episode_Length_minutes\"\n",
    "    tmp = X_train.groupby(col).Listening_Time_minutes.apply(quant)\n",
    "    tmp.columns = [f\"TE1_elm_{s}\" for s in tmp.columns]\n",
    "    X_valid = X_valid.merge(tmp, on=col, how=\"left\")\n",
    "    X_test = X_test.merge(tmp, on=col, how=\"left\")\n",
    "\n",
    "    ### FEATURE SET 2 (uses Listening_Time_minutes) ###\n",
    "    for col in CAT_COLS:\n",
    "        tmp = X_train.groupby(col).Listening_Time_minutes.apply(quant)\n",
    "        tmp.columns = [f\"TE2_{col}_{s}\" for s in tmp.columns]\n",
    "        X_valid = X_valid.merge(tmp, on=col, how=\"left\")\n",
    "        X_test = X_test.merge(tmp, on=col, how=\"left\")\n",
    "\n",
    "    ### FEATURE SET 3 (does not use Listening_Time_minutes) ###\n",
    "    for col in CAT_COLS:\n",
    "        col2 = \"Episode_Length_minutes\"\n",
    "        tmp = X_train.groupby(col)[col2].apply(quant)\n",
    "        tmp.columns = [f\"FE3_{col}_elm_{s}\" for s in tmp.columns]\n",
    "        X_train = X_train.merge(tmp, on=col, how=\"left\")\n",
    "        X_valid = X_valid.merge(tmp, on=col, how=\"left\")\n",
    "        X_test = X_test.merge(tmp, on=col, how=\"left\")\n",
    "\n",
    "    # CONVERT TO CAT_COLS SO XGBOOST RECOGNIZES THEM\n",
    "    X_train[CAT_COLS] = X_train[CAT_COLS].astype(\"category\")\n",
    "    X_valid[CAT_COLS] = X_valid[CAT_COLS].astype(\"category\")\n",
    "    X_test[CAT_COLS] = X_test[CAT_COLS].astype(\"category\")\n",
    "\n",
    "    # DROP Listening_Time_minutes THAT WAS USED FOR TARGET ENCODING\n",
    "    X_train = X_train.drop(TARGET_COL, axis=1)\n",
    "\n",
    "    # BUILD MODEL\n",
    "    model = XGBRegressor(\n",
    "        **ParamsXGB,\n",
    "        random_state=42,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "\n",
    "    # TRAIN MODEL\n",
    "    COLS = X_train.columns\n",
    "    model.fit(\n",
    "        X_train[COLS], y_train,\n",
    "        eval_set=[(X_valid[COLS], y_valid)],\n",
    "        verbose=100        \n",
    "    )\n",
    "\n",
    "    # PREDICT OOF AND TEST\n",
    "    oof[test_index] = model.predict(X_valid[COLS])\n",
    "    pred += model.predict(X_test[COLS])\n",
    "    \n",
    "    fold_rmse = mean_squared_error(y_valid, oof[test_index]) ** 0.5\n",
    "    print(f\"✅ Fold {i + 1} RMSE: {fold_rmse:.5f}\")\n",
    "\n",
    "overall_rmse = mean_squared_error(y, oof) ** 0.5\n",
    "print(f\"\\n🎯 Overall CV RMSE: {overall_rmse:.5f}\")\n",
    "pred /= FOLDS"
   ],
   "id": "34865f27859aada5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OUTER Fold 1 ###\n",
      " ## INNER Fold 1 (outer fold 1) ##\n",
      " ## INNER Fold 2 (outer fold 1) ##\n",
      " ## INNER Fold 3 (outer fold 1) ##\n",
      " ## INNER Fold 4 (outer fold 1) ##\n",
      " ## INNER Fold 5 (outer fold 1) ##\n",
      "[0]\tvalidation_0-rmse:27.03280\n",
      "[100]\tvalidation_0-rmse:19.94468\n",
      "[200]\tvalidation_0-rmse:16.20956\n",
      "[300]\tvalidation_0-rmse:14.38583\n",
      "[400]\tvalidation_0-rmse:13.54342\n",
      "[500]\tvalidation_0-rmse:13.15684\n",
      "[600]\tvalidation_0-rmse:12.97178\n",
      "[700]\tvalidation_0-rmse:12.87902\n",
      "[800]\tvalidation_0-rmse:12.83093\n",
      "[900]\tvalidation_0-rmse:12.80467\n",
      "[1000]\tvalidation_0-rmse:12.78802\n",
      "[1100]\tvalidation_0-rmse:12.77706\n",
      "[1200]\tvalidation_0-rmse:12.77030\n",
      "[1300]\tvalidation_0-rmse:12.76636\n",
      "[1400]\tvalidation_0-rmse:12.76527\n",
      "[1496]\tvalidation_0-rmse:12.76569\n",
      "✅ Fold 1 RMSE: 12.76511\n",
      "### OUTER Fold 2 ###\n",
      " ## INNER Fold 1 (outer fold 2) ##\n",
      " ## INNER Fold 2 (outer fold 2) ##\n",
      " ## INNER Fold 3 (outer fold 2) ##\n",
      " ## INNER Fold 4 (outer fold 2) ##\n",
      " ## INNER Fold 5 (outer fold 2) ##\n",
      "[0]\tvalidation_0-rmse:27.06442\n",
      "[100]\tvalidation_0-rmse:19.98703\n",
      "[200]\tvalidation_0-rmse:16.26315\n",
      "[300]\tvalidation_0-rmse:14.44709\n",
      "[400]\tvalidation_0-rmse:13.60764\n",
      "[500]\tvalidation_0-rmse:13.22387\n",
      "[600]\tvalidation_0-rmse:13.03946\n",
      "[700]\tvalidation_0-rmse:12.94681\n",
      "[800]\tvalidation_0-rmse:12.89765\n",
      "[900]\tvalidation_0-rmse:12.87032\n",
      "[1000]\tvalidation_0-rmse:12.85360\n",
      "[1100]\tvalidation_0-rmse:12.84258\n",
      "[1200]\tvalidation_0-rmse:12.83586\n",
      "[1300]\tvalidation_0-rmse:12.83282\n",
      "[1400]\tvalidation_0-rmse:12.83224\n",
      "[1465]\tvalidation_0-rmse:12.83384\n",
      "✅ Fold 2 RMSE: 12.83179\n",
      "### OUTER Fold 3 ###\n",
      " ## INNER Fold 1 (outer fold 3) ##\n",
      " ## INNER Fold 2 (outer fold 3) ##\n",
      " ## INNER Fold 3 (outer fold 3) ##\n",
      " ## INNER Fold 4 (outer fold 3) ##\n",
      " ## INNER Fold 5 (outer fold 3) ##\n",
      "[0]\tvalidation_0-rmse:27.03350\n",
      "[100]\tvalidation_0-rmse:19.96405\n",
      "[200]\tvalidation_0-rmse:16.24637\n",
      "[300]\tvalidation_0-rmse:14.43390\n",
      "[400]\tvalidation_0-rmse:13.59714\n",
      "[500]\tvalidation_0-rmse:13.21382\n",
      "[600]\tvalidation_0-rmse:13.03014\n",
      "[700]\tvalidation_0-rmse:12.93827\n",
      "[800]\tvalidation_0-rmse:12.88991\n",
      "[900]\tvalidation_0-rmse:12.86379\n",
      "[1000]\tvalidation_0-rmse:12.84787\n",
      "[1100]\tvalidation_0-rmse:12.83615\n",
      "[1200]\tvalidation_0-rmse:12.82993\n",
      "[1300]\tvalidation_0-rmse:12.82515\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:88\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:729\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    728\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 729\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/sklearn.py:1247\u001B[0m, in \u001B[0;36mXGBModel.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001B[0m\n\u001B[1;32m   1244\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1245\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1247\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1248\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1249\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1250\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1251\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_evaluation_result(evals_result)\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:729\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    728\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 729\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:184\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    183\u001B[0m     bst\u001B[38;5;241m.\u001B[39mupdate(dtrain, iteration\u001B[38;5;241m=\u001B[39mi, fobj\u001B[38;5;241m=\u001B[39mobj)\n\u001B[0;32m--> 184\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mcb_container\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mafter_iteration\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevals\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    185\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    187\u001B[0m bst \u001B[38;5;241m=\u001B[39m cb_container\u001B[38;5;241m.\u001B[39mafter_training(bst)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/callback.py:264\u001B[0m, in \u001B[0;36mCallbackContainer.after_iteration\u001B[0;34m(self, model, epoch, dtrain, evals)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, name \u001B[38;5;129;01min\u001B[39;00m evals:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m name\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset name should not contain `-`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 264\u001B[0m score: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_set\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_output_margin\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    265\u001B[0m metric_score \u001B[38;5;241m=\u001B[39m _parse_eval_str(score)\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_history(metric_score, epoch)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:2353\u001B[0m, in \u001B[0;36mBooster.eval_set\u001B[0;34m(self, evals, iteration, feval, output_margin)\u001B[0m\n\u001B[1;32m   2350\u001B[0m evnames \u001B[38;5;241m=\u001B[39m c_array(ctypes\u001B[38;5;241m.\u001B[39mc_char_p, [c_str(d[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m evals])\n\u001B[1;32m   2351\u001B[0m msg \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mc_char_p()\n\u001B[1;32m   2352\u001B[0m _check_call(\n\u001B[0;32m-> 2353\u001B[0m     \u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterEvalOneIter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2354\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2355\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2356\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdmats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2357\u001B[0m \u001B[43m        \u001B[49m\u001B[43mevnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2358\u001B[0m \u001B[43m        \u001B[49m\u001B[43mc_bst_ulong\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mevals\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2359\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2360\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2361\u001B[0m )\n\u001B[1;32m   2362\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m msg\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2363\u001B[0m res \u001B[38;5;241m=\u001B[39m msg\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;241m.\u001B[39mdecode()  \u001B[38;5;66;03m# pylint: disable=no-member\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Overall CV Score\n",
    "Below we display overall cv score and save oof predictions to disk, so we can use them later to assist finding ensemble weights with our other models."
   ],
   "id": "aa20014ace42ddd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:29:18.320827Z",
     "start_time": "2025-04-26T18:29:18.306766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# COMPUTE OVERALL CV SCORE\n",
    "true = train.Listening_Time_minutes.values\n",
    "s = np.sqrt(mean_squared_error(true, oof))\n",
    "print(f\"CV Score = {s}\")"
   ],
   "id": "adba9dcadd20bff2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score = 41.78109393786513\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# XGB Feature Importance\n",
    "Here is XGBoost feature importance sorted by `gain`."
   ],
   "id": "2946448b89de7664"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:29:18.922355Z",
     "start_time": "2025-04-26T18:29:18.322214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 20))\n",
    "xgb.plot_importance(model, max_num_features=100, importance_type='gain', ax=ax)\n",
    "plt.title(\"Top 100 Feature Importances (XGBoost)\")\n",
    "plt.show()"
   ],
   "id": "1f8b87b98c7b69b6",
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mxgboost\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mxgb\u001B[39;00m\n\u001B[1;32m      3\u001B[0m fig, ax \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m20\u001B[39m))\n\u001B[0;32m----> 4\u001B[0m \u001B[43mxgb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot_importance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_num_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimportance_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43max\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTop 100 Feature Importances (XGBoost)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:729\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    728\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 729\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/plotting.py:91\u001B[0m, in \u001B[0;36mplot_importance\u001B[0;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, values_format, **kwargs)\u001B[0m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou must install matplotlib to plot importance\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(booster, XGBModel):\n\u001B[0;32m---> 91\u001B[0m     importance \u001B[38;5;241m=\u001B[39m \u001B[43mbooster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_booster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mget_score(\n\u001B[1;32m     92\u001B[0m         importance_type\u001B[38;5;241m=\u001B[39mimportance_type, fmap\u001B[38;5;241m=\u001B[39mfmap\n\u001B[1;32m     93\u001B[0m     )\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(booster, Booster):\n\u001B[1;32m     95\u001B[0m     importance \u001B[38;5;241m=\u001B[39m booster\u001B[38;5;241m.\u001B[39mget_score(importance_type\u001B[38;5;241m=\u001B[39mimportance_type, fmap\u001B[38;5;241m=\u001B[39mfmap)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/sklearn.py:922\u001B[0m, in \u001B[0;36mXGBModel.get_booster\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__sklearn_is_fitted__():\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NotFittedError\n\u001B[0;32m--> 922\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mneed to call fit or load_model beforehand\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    923\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster\n",
      "\u001B[0;31mNotFittedError\u001B[0m: need to call fit or load_model beforehand"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x2000 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Make Submission CSV\n",
    "We save our test predictions to submission.csv and plot our predictions. "
   ],
   "id": "740361ecf0700418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sub = pd.read_csv(\"data/sample_submission.csv\")\n",
    "sub.Listening_Time_minutes = pred\n",
    "sub.to_csv(f\"submission_v{VER}.csv\", index=False)\n",
    "sub.head()"
   ],
   "id": "a452a0d9477f5465",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:29:18.929718Z",
     "start_time": "2025-04-26T18:29:18.929667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(sub.Listening_Time_minutes, bins=100)\n",
    "plt.title(\"Test Predictions\")\n",
    "plt.show()"
   ],
   "id": "84df4890f309d5e0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
