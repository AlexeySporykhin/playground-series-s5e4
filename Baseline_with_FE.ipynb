{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:19.793522Z",
     "start_time": "2025-05-02T10:07:19.781016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CUDA = False\n",
    "if CUDA:\n",
    "    !pip install -qq scikit-learn==1.6.1"
   ],
   "id": "4233558a7c75e5f3",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:19.817691Z",
     "start_time": "2025-05-02T10:07:19.814753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##\n",
    "if CUDA:\n",
    "    %load_ext cudf.pandas\n",
    "    import cudf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations"
   ],
   "id": "52041f54259396d6",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:20.602121Z",
     "start_time": "2025-05-02T10:07:19.823547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if CUDA:\n",
    "    test = pd.read_csv('/kaggle/input/playground-series-s5e4/test.csv', index_col='id')\n",
    "    train = pd.read_csv('/kaggle/input/playground-series-s5e4/train.csv', index_col='id')\n",
    "    print(train.shape)\n",
    "else:\n",
    "    test = pd.read_csv('data/test.csv', index_col='id')\n",
    "    train = pd.read_csv('data/train.csv', index_col='id')\n",
    "    print(train.shape)"
   ],
   "id": "e8bab2d880f2257d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 11)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:20.605445Z",
     "start_time": "2025-05-02T10:07:20.603433Z"
    }
   },
   "cell_type": "code",
   "source": "warnings.filterwarnings('ignore')",
   "id": "1607bb44c9ca7bba",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:20.608473Z",
     "start_time": "2025-05-02T10:07:20.606461Z"
    }
   },
   "cell_type": "code",
   "source": "pd.options.display.max_columns = None",
   "id": "d2e23c56a02a6836",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FE",
   "id": "7912cfd1a2ad608b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:20.616586Z",
     "start_time": "2025-05-02T10:07:20.610100Z"
    }
   },
   "cell_type": "code",
   "source": "y = train['Listening_Time_minutes']",
   "id": "a3fee948c6ac8a57",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:20.619705Z",
     "start_time": "2025-05-02T10:07:20.617578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TARGET_COL = ['Listening_Time_minutes']\n",
    "CAT_COLS = ['Podcast_Name', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']"
   ],
   "id": "7b2b0048806758af",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:22.906406Z",
     "start_time": "2025-05-02T10:07:20.620504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "def feature_eng(df):\n",
    "    podc_dict = {'Mystery Matters': 0, 'Joke Junction': 1, 'Study Sessions': 2, 'Digital Digest': 3, 'Mind & Body': 4,\n",
    "                 'Fitness First': 5, 'Criminal Minds': 6, 'News Roundup': 7, 'Daily Digest': 8, 'Music Matters': 9,\n",
    "                 'Sports Central': 10, 'Melody Mix': 11, 'Game Day': 12, 'Gadget Geek': 13, 'Global News': 14,\n",
    "                 'Tech Talks': 15, 'Sport Spot': 16, 'Funny Folks': 17, 'Sports Weekly': 18, 'Business Briefs': 19,\n",
    "                 'Tech Trends': 20, 'Innovators': 21, 'Health Hour': 22, 'Comedy Corner': 23, 'Sound Waves': 24,\n",
    "                 'Brain Boost': 25, \"Athlete's Arena\": 26, 'Wellness Wave': 27, 'Style Guide': 28, 'World Watch': 29,\n",
    "                 'Humor Hub': 30, 'Money Matters': 31, 'Healthy Living': 32, 'Home & Living': 33,\n",
    "                 'Educational Nuggets': 34, 'Market Masters': 35, 'Learning Lab': 36, 'Lifestyle Lounge': 37,\n",
    "                 'Crime Chronicles': 38, 'Detective Diaries': 39, 'Life Lessons': 40, 'Current Affairs': 41,\n",
    "                 'Finance Focus': 42, 'Laugh Line': 43, 'True Crime Stories': 44, 'Business Insights': 45,\n",
    "                 'Fashion Forward': 46, 'Tune Time': 47}\n",
    "    genr_dict = {'True Crime': 0, 'Comedy': 1, 'Education': 2, 'Technology': 3, 'Health': 4, 'News': 5, 'Music': 6,\n",
    "                 'Sports': 7, 'Business': 8, 'Lifestyle': 9}\n",
    "    week_dict = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6}\n",
    "    time_dict = {'Morning': 0, 'Afternoon': 1, 'Evening': 2, 'Night': 3}\n",
    "    sent_dict = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
    "\n",
    "    df['Episode_Num'] = df['Episode_Title'].str[8:]\n",
    "\n",
    "    df['Genre'] = df['Genre'].replace(genr_dict)\n",
    "    df['Podcast_Name'] = df['Podcast_Name'].replace(podc_dict)\n",
    "    df['Publication_Day'] = df['Publication_Day'].replace(week_dict)\n",
    "    df['Publication_Time'] = df['Publication_Time'].replace(time_dict)\n",
    "    df['Episode_Sentiment'] = df['Episode_Sentiment'].replace(sent_dict)\n",
    "\n",
    "    df['Genre'] = df['Genre']\n",
    "    df['Podcast_Name'] = df['Podcast_Name']\n",
    "    df['Publication_Day'] = df['Publication_Day']\n",
    "    df['Publication_Time'] = df['Publication_Time']\n",
    "    df['Episode_Sentiment'] = df['Episode_Sentiment']\n",
    "\n",
    "    df = df.drop(columns=['Episode_Title'])\n",
    "\n",
    "    df['Episode_Length_minutes'] = df['Episode_Length_minutes'].astype('float32')\n",
    "    df['Host_Popularity_percentage'] = df['Host_Popularity_percentage'].astype('float32')\n",
    "    df['Guest_Popularity_percentage'] = df['Guest_Popularity_percentage'].astype('float32')\n",
    "    df['Number_of_Ads'] = df['Number_of_Ads'].astype('float32')\n",
    "    df['LinearFeat'] = 0.728*df['Episode_Length_minutes']\n",
    "    df['Is_High_Host_Popularity'] = (df['Host_Popularity_percentage'] > 70).astype(int)\n",
    "    # df['Is_High_Guest_Popularity'] = (df['Guest_Popularity_percentage'] > 70).astype(int)\n",
    "    # df['Host_Guest_Popularity_Gap'] = df['Host_Popularity_percentage'] / df['Guest_Popularity_percentage']\n",
    "    # df['Host_Guest_Popularity_Gap'] = df['Host_Guest_Popularity_Gap'].replace([np.inf, -np.inf], np.nan)\n",
    "    # df['Ad_Density'] = df['Number_of_Ads'] / df['Episode_Length_minutes']\n",
    "    # df['Ad_Density'] = df['Ad_Density'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = feature_eng(train)\n",
    "test = feature_eng(test)\n",
    "\n",
    "train['Listening_Time_minutes'] = train['Listening_Time_minutes'].astype('float32')\n",
    "CAT_COLS.append('Episode_Num')"
   ],
   "id": "940090fe2959baef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.09 s, sys: 175 ms, total: 2.27 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Combination of Categorical Columns",
   "id": "baba0ed5d37c80a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:25.534025Z",
     "start_time": "2025-05-02T10:07:22.907142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "encode_columns = ['Episode_Length_minutes', 'Episode_Num']\n",
    "\n",
    "pair_size = [2]\n",
    "COMBO = []\n",
    "if CUDA:\n",
    "    train = cudf.from_pandas(train)\n",
    "    test = cudf.from_pandas(test)\n",
    "\n",
    "    for r in pair_size:\n",
    "        for cols in tqdm(list(combinations(encode_columns, r))):\n",
    "            new_col_name = '_'.join(cols)\n",
    "\n",
    "            train[new_col_name] = train[cols[0]].astype(str)\n",
    "            for col in cols[1:]:\n",
    "                train[new_col_name] = train[new_col_name] + '_' + train[col].astype(str)\n",
    "\n",
    "            test[new_col_name] = test[cols[0]].astype(str)\n",
    "            for col in cols[1:]:\n",
    "                test[new_col_name] = test[new_col_name] + '_' + test[col].astype(str)\n",
    "\n",
    "            COMBO.append(new_col_name)\n",
    "\n",
    "    train = train.to_pandas()\n",
    "    test = test.to_pandas()\n",
    "else:\n",
    "    for r in pair_size:\n",
    "        for cols in tqdm(list(combinations(encode_columns, r))):\n",
    "            new_col_name = '_'.join(cols)\n",
    "            train[new_col_name] = train[list(cols)].astype(str).agg('_'.join, axis=1)\n",
    "            test[new_col_name] = test[list(cols)].astype(str).agg('_'.join, axis=1)\n",
    "            COMBO.append(new_col_name)"
   ],
   "id": "209b60d34c93c54e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.54 s, sys: 57.5 ms, total: 2.6 s\n",
      "Wall time: 2.62 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create columns lists",
   "id": "aa1c9c4d3da45912"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:25.536799Z",
     "start_time": "2025-05-02T10:07:25.534829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_COLS = [col for col in train.columns if col not in CAT_COLS + TARGET_COL + COMBO]\n",
    "FEATURES = CAT_COLS + NUM_COLS + COMBO"
   ],
   "id": "89f06194fbe33305",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:07:25.539458Z",
     "start_time": "2025-05-02T10:07:25.537924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# STATISTICS TO AGGREGATE FOR OUR FEATURE GROUPS\n",
    "STATS = ['mean']"
   ],
   "id": "6038e5121800dea7",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## KFOLD ",
   "id": "2a10272f79e871aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:09:12.763183Z",
     "start_time": "2025-05-02T10:07:25.541390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "ParamsXGB = {'max_depth': 10, 'learning_rate': 0.00462847749422193, 'min_child_weight': 4,\n",
    "             'subsample': 0.8244361720956633, 'colsample_bytree': 0.5586626138810886,\n",
    "             'gamma': 1.1614500954011453, 'reg_alpha': 0.3548920754067436, 'reg_lambda': 3.9465129148897287,\n",
    "             \"n_estimators\": 10000, 'enable_categorical': True,\n",
    "             }\n",
    "\n",
    "FOLDS = 7\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "oof = np.zeros((len(train)))\n",
    "pred = np.zeros((len(test)))\n",
    "\n",
    "# OUTER K FOLD\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    print(f\"### OUTER Fold {i + 1} ###\")\n",
    "\n",
    "    X_train = train.loc[train_index, FEATURES + TARGET_COL].reset_index(drop=True).copy()\n",
    "    y_train = train.loc[train_index, 'Listening_Time_minutes']\n",
    "\n",
    "    X_valid = train.loc[test_index, FEATURES].reset_index(drop=True).copy()\n",
    "    y_valid = train.loc[test_index, 'Listening_Time_minutes']\n",
    "\n",
    "    X_test = test[FEATURES].reset_index(drop=True).copy()\n",
    "\n",
    "    # INNER K FOLD (TO PREVENT LEAKAGE WHEN USING Listening_Time_minutes)\n",
    "    kf2 = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    for j, (train_index2, test_index2) in enumerate(kf2.split(X_train)):\n",
    "        print(f\" ## INNER Fold {j + 1} (outer fold {i + 1}) ##\")\n",
    "\n",
    "        X_train2 = X_train.loc[train_index2, FEATURES + TARGET_COL].copy()\n",
    "        X_valid2 = X_train.loc[test_index2, FEATURES].copy()\n",
    "\n",
    "        ## FEATURE SET 2 (uses Listening_Time_minutes) ###\n",
    "        for col in COMBO:\n",
    "            tmp = X_train2.groupby(col).Listening_Time_minutes.agg(STATS)\n",
    "            tmp.columns = [f\"TE2_{col}_{s}\" for s in STATS]\n",
    "            X_valid2 = X_valid2.merge(tmp, on=col, how=\"left\")\n",
    "            for c in tmp.columns:\n",
    "                X_train.loc[test_index2, c] = X_valid2[c].values\n",
    "    ## FEATURE SET 2 (uses Listening_Time_minutes) ###\n",
    "    for col in COMBO:\n",
    "        tmp = X_train.groupby(col).Listening_Time_minutes.agg(STATS)\n",
    "        tmp.columns = [f\"TE2_{col}_{s}\" for s in STATS]\n",
    "        X_valid = X_valid.merge(tmp, on=col, how=\"left\")\n",
    "        X_test = X_test.merge(tmp, on=col, how=\"left\")\n",
    "\n",
    "    # CONVERT TO CAT_COLS SO XGBOOST RECOGNIZES THEM\n",
    "    X_train[CAT_COLS] = X_train[CAT_COLS].astype(\"category\")\n",
    "    X_valid[CAT_COLS] = X_valid[CAT_COLS].astype(\"category\")\n",
    "    X_test[CAT_COLS] = X_test[CAT_COLS].astype(\"category\")\n",
    "\n",
    "    # DROP Listening_Time_minutes THAT WAS USED FOR TARGET ENCODING\n",
    "    X_train = X_train.drop(TARGET_COL + COMBO, axis=1)\n",
    "    X_valid = X_valid.drop(COMBO, axis=1)\n",
    "    X_test = X_test.drop(COMBO, axis=1)\n",
    "\n",
    "    # BUILD MODEL\n",
    "    if CUDA:\n",
    "        model = XGBRegressor(\n",
    "            **ParamsXGB,\n",
    "            tree_method='gpu_hist',\n",
    "            random_state=42,\n",
    "            early_stopping_rounds=100\n",
    "        )\n",
    "    else:\n",
    "        model = XGBRegressor(\n",
    "            **ParamsXGB,\n",
    "            tree_method='hist',\n",
    "            random_state=42,\n",
    "            early_stopping_rounds=100\n",
    "        )\n",
    "\n",
    "        # TRAIN MODEL\n",
    "    COLS = X_train.columns\n",
    "    model.fit(\n",
    "        X_train[COLS], y_train,\n",
    "        eval_set=[(X_valid[COLS], y_valid)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    # PREDICT OOF AND TEST\n",
    "    oof[test_index] = model.predict(X_valid[COLS])\n",
    "    pred += model.predict(X_test[COLS])\n",
    "\n",
    "    fold_rmse = mean_squared_error(y_valid, oof[test_index]) ** 0.5\n",
    "    print(f\"✅ Fold {i + 1} RMSE: {fold_rmse:.5f}\")\n",
    "\n",
    "overall_rmse = mean_squared_error(y, oof) ** 0.5\n",
    "print(f\"\\n🎯 Overall CV RMSE: {overall_rmse:.5f}\")\n",
    "pred /= FOLDS"
   ],
   "id": "34865f27859aada5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OUTER Fold 1 ###\n",
      " ## INNER Fold 1 (outer fold 1) ##\n",
      " ## INNER Fold 2 (outer fold 1) ##\n",
      " ## INNER Fold 3 (outer fold 1) ##\n",
      " ## INNER Fold 4 (outer fold 1) ##\n",
      " ## INNER Fold 5 (outer fold 1) ##\n",
      " ## INNER Fold 6 (outer fold 1) ##\n",
      " ## INNER Fold 7 (outer fold 1) ##\n",
      "[0]\tvalidation_0-rmse:27.07688\n",
      "[100]\tvalidation_0-rmse:20.60138\n",
      "[200]\tvalidation_0-rmse:16.95204\n",
      "[300]\tvalidation_0-rmse:14.79652\n",
      "[400]\tvalidation_0-rmse:13.77065\n",
      "[500]\tvalidation_0-rmse:13.28876\n",
      "[600]\tvalidation_0-rmse:13.07079\n",
      "[700]\tvalidation_0-rmse:12.95548\n",
      "[800]\tvalidation_0-rmse:12.89219\n",
      "[900]\tvalidation_0-rmse:12.85720\n",
      "[1000]\tvalidation_0-rmse:12.83579\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:75\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:729\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    728\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 729\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/sklearn.py:1247\u001B[0m, in \u001B[0;36mXGBModel.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001B[0m\n\u001B[1;32m   1244\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1245\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1247\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1248\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1249\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1250\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1251\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_evaluation_result(evals_result)\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:729\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    728\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 729\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m--> 183\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miteration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:2247\u001B[0m, in \u001B[0;36mBooster.update\u001B[0;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[1;32m   2243\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_dmatrix_features(dtrain)\n\u001B[1;32m   2245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2246\u001B[0m     _check_call(\n\u001B[0;32m-> 2247\u001B[0m         \u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2248\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\n\u001B[1;32m   2249\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2250\u001B[0m     )\n\u001B[1;32m   2251\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2252\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:09:12.766144Z",
     "start_time": "2025-05-02T10:09:12.764475Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3e0203fc27df6c16",
   "outputs": [],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
